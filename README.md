# Next.js AI Chat App (with Testune Integration)

This is a **Next.js AI Chat App** template with built-in integration for [Testune](https://testune.xyz), making it easy to experiment with and optimize your LLM prompts.

---

## ğŸš€ Features

-   âš¡ Next.js 14 (App Router)
-   ğŸ“ Pre-configured Testune SDK for prompt A/B testing
-   ğŸ”‘ Bring Your Own LLM API key (OpenAI)
-   ğŸ“Š Feedback & analytics pipeline via Testune
-   ğŸ’¬ Ready-to-use chat interface

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ app/                # Next.js app router pages
â”œâ”€â”€ components/         # Reusable React components
â”œâ”€â”€ lib/                # Testune + LLM utilities
â”œâ”€â”€ styles/             # Global styles
â””â”€â”€ package.json
```

---

## ğŸ”§ Setup

### 1. Clone the repo

```bash
git clone https://github.com/your-org/nextjs-ai-chat-app.git
cd nextjs-ai-chat-app
```

### 2. Install dependencies

```bash
npm install
# or
yarn install
```

### 3. Configure environment variables

Create a `.env.local` file with:

```bash
NEXT_PUBLIC_TESTUNE_API_KEY=your_testune_api_key
NEXT_PUBLIC_LLM_API_KEY=your_llm_api_key
```

### 4. Run locally

```bash
npm run dev
```

---

## ğŸ“Š Using Testune

This template comes pre-wired with **Testune analytics and A/B testing** for LLM prompts.

Example usage:

```ts
import { testuneClient } from "@/lib/testune";

async function getResponse(userMessage: string) {
	const response = await testuneClient.sendMessage({
		message: userMessage,
		promptGroup: "chat-prompt-v1",
	});

	return response;
}
```

You can monitor performance and run A/B tests directly from the [Testune dashboard](https://testune.xyz).

---

## ğŸ§‘â€ğŸ’» Example Usage

1. Run the app locally (`npm run dev`).
2. Open the chat UI at [http://localhost:3000](http://localhost:3000).
3. Enter a message and see the Testune-powered LLM respond.
4. Check the dashboard for analytics.

---

## ğŸ“œ License

MIT License. See [LICENSE](./LICENSE) for details.
